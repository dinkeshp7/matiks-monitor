name: Matiks Scraper Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */6 * * *"   # every 6 hours (UTC)

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      PYTHONUNBUFFERED: "1"
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
      REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
      REDDIT_USER_AGENT: matiks-monitor
      PLAYSTORE_APP_ID: ${{ secrets.PLAYSTORE_APP_ID }}
      APPSTORE_APP_ID: ${{ secrets.APPSTORE_APP_ID }}

    steps:
      # -----------------------------
      # Checkout Repository
      # -----------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # -----------------------------
      # Setup Python
      # -----------------------------
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # -----------------------------
      # Cache pip dependencies
      # -----------------------------
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # -----------------------------
      # Cache HuggingFace model
      # (Prevents re-downloading transformer model)
      # -----------------------------
      - name: Cache HuggingFace model
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: hf-model-cache

      # -----------------------------
      # Debug (verify correct file)
      # -----------------------------
      - name: Debug root requirements
        run: |
          echo "===== USING ROOT REQUIREMENTS ====="
          cat ./requirements.txt

      # -----------------------------
      # Install dependencies
      # -----------------------------
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r ./requirements.txt

      # -----------------------------
      # Run scraper pipeline
      # -----------------------------
      - name: Run scraper pipeline
        run: |
          python -m scripts.run_all

      # -----------------------------
      # Optional: Notify on failure
      # -----------------------------
      - name: Notify on failure
        if: failure()
        run: |
          echo "Scraper pipeline failed."